{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Minibatch [10/90], Loss: 0.8829, Accuracy: 0.6062\n",
      "Epoch [1/2], Minibatch [20/90], Loss: 0.7106, Accuracy: 0.7516\n",
      "Epoch [1/2], Minibatch [30/90], Loss: 0.5896, Accuracy: 0.7974\n",
      "Epoch [1/2], Minibatch [40/90], Loss: 0.5066, Accuracy: 0.8313\n",
      "Epoch [1/2], Minibatch [50/90], Loss: 0.4479, Accuracy: 0.8516\n",
      "Epoch [1/2], Minibatch [60/90], Loss: 0.3986, Accuracy: 0.8714\n",
      "Epoch [1/2], Minibatch [70/90], Loss: 0.3676, Accuracy: 0.8824\n",
      "Epoch [1/2], Minibatch [80/90], Loss: 0.3372, Accuracy: 0.8943\n",
      "Epoch [1/2], Minibatch [90/90], Loss: 0.3139, Accuracy: 0.9027\n",
      "Epoch [1/2], Loss: 0.3139, Accuracy: 0.9027\n",
      "Epoch [2/2], Minibatch [10/90], Loss: 0.1102, Accuracy: 0.9766\n",
      "Epoch [2/2], Minibatch [20/90], Loss: 0.1083, Accuracy: 0.9773\n",
      "Epoch [2/2], Minibatch [30/90], Loss: 0.0961, Accuracy: 0.9818\n",
      "Epoch [2/2], Minibatch [40/90], Loss: 0.0933, Accuracy: 0.9824\n",
      "Epoch [2/2], Minibatch [50/90], Loss: 0.0918, Accuracy: 0.9822\n",
      "Epoch [2/2], Minibatch [60/90], Loss: 0.0903, Accuracy: 0.9823\n",
      "Epoch [2/2], Minibatch [70/90], Loss: 0.0917, Accuracy: 0.9817\n",
      "Epoch [2/2], Minibatch [80/90], Loss: 0.0906, Accuracy: 0.9814\n",
      "Epoch [2/2], Minibatch [90/90], Loss: 0.0883, Accuracy: 0.9822\n",
      "Epoch [2/2], Loss: 0.0883, Accuracy: 0.9822\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from PIL import Image\n",
    "\n",
    "class HierarchicalResNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(HierarchicalResNet, self).__init__()\n",
    "        self.resnet = resnet18(pretrained=True)\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        self.fc_class = nn.Linear(num_ftrs, num_classes) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.resnet(x)\n",
    "        class_output = self.fc_class(features)\n",
    "        return class_output\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class HierarchicalDataset(Dataset):\n",
    "    def __init__(self, data_dirs, transform=None):\n",
    "        self.data = []\n",
    "        self.class_map = {}\n",
    "        class_idx = 0\n",
    "        for class_dir in data_dirs:\n",
    "            class_label = os.path.basename(class_dir)\n",
    "            self.class_map[class_idx] = class_label\n",
    "            for sub_dir in os.listdir(class_dir):\n",
    "                sub_dir_path = os.path.join(class_dir, sub_dir)\n",
    "                if os.path.isdir(sub_dir_path):\n",
    "                    for img_file in os.listdir(sub_dir_path):\n",
    "                        img_path = os.path.join(sub_dir_path, img_file)\n",
    "                        _, ext = os.path.splitext(img_path)\n",
    "                        if ext.lower() in ['.jpg', '.jpeg', '.png', '.bmp', '.gif']: \n",
    "                            img = Image.open(img_path)\n",
    "                            if img.mode == 'RGB': \n",
    "                                self.data.append((img_path, class_idx))\n",
    "            class_idx += 1\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, class_idx = self.data[idx]\n",
    "        img = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, class_idx\n",
    "\n",
    "train_dirs = [\n",
    "    '../Image Data/Dance/train',\n",
    "    '../Image Data/Monuments/train',\n",
    "    '../Image Data/Paintings/training'\n",
    "]\n",
    "\n",
    "train_dataset = HierarchicalDataset(train_dirs, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "num_classes = 3  \n",
    "model = HierarchicalResNet(num_classes=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 2\n",
    "print_every = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    minibatch_counter = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        minibatch_counter += 1\n",
    "        if minibatch_counter % print_every == 0:\n",
    "            minibatch_loss = running_loss / total\n",
    "            minibatch_accuracy = correct / total\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Minibatch [{minibatch_counter}/{len(train_loader)}], Loss: {minibatch_loss:.4f}, Accuracy: {minibatch_accuracy:.4f}')\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_accuracy = correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
    "torch.save(model.state_dict(), 'HierarchicalClassificationModel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomResNet, self).__init__()\n",
    "        self.resnet = resnet18(pretrained=True)\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data = ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "train_dir = '../Image Data/Paintings/training'\n",
    "val_dir = '../Image Data/Paintings/testing'\n",
    "train_dataset = CustomDataset(train_dir, transform=transform)\n",
    "val_dataset = CustomDataset(val_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "num_classes = 8\n",
    "model = CustomResNet(num_classes)\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "print_every = 7 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    minibatch_counter = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        minibatch_counter += 1\n",
    "        if minibatch_counter % print_every == 0:\n",
    "            minibatch_loss = running_loss / total\n",
    "            minibatch_accuracy = correct / total\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Minibatch [{minibatch_counter}/{len(train_loader)}], Loss: {minibatch_loss:.4f}, Accuracy: {minibatch_accuracy:.4f}')\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_accuracy = correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
    "    # model.eval()\n",
    "    # val_loss = 0.0\n",
    "    # val_correct = 0\n",
    "    # val_total = 0\n",
    "    # minibatch_counter = 0\n",
    "    # with torch.no_grad():\n",
    "    #     for inputs, labels in val_loader:\n",
    "    #         outputs = model(inputs)\n",
    "    #         loss = criterion(outputs, labels)\n",
    "    #         val_loss += loss.item() * inputs.size(0)\n",
    "    #         _, predicted = torch.max(outputs, 1)\n",
    "    #         val_total += labels.size(0)\n",
    "    #         val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    #         minibatch_counter += 1\n",
    "    #         if minibatch_counter % print_every == 0:\n",
    "    #             minibatch_loss = val_loss / val_total\n",
    "    #             minibatch_accuracy = val_correct / val_total\n",
    "    #             print(f'>>>>> Minibatch [{minibatch_counter}/{len(val_loader)}], Loss: {minibatch_loss:.4f}, Accuracy: {minibatch_accuracy:.4f}')\n",
    "\n",
    "    # val_epoch_loss = val_loss / len(val_dataset)\n",
    "    # val_epoch_accuracy = val_correct / val_total\n",
    "    # print(f'Validation [{epoch+1}/{num_epochs}], Loss: {val_epoch_loss:.4f}, Accuracy: {val_epoch_accuracy:.4f}')\n",
    "\n",
    "print('Fine-tuning finished.')\n",
    "torch.save(model.state_dict(), 'Painting.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: ../Image Data/Monuments/train/Ajanta Caves/(1).jpg, Image belongs to a different category.\n",
      "Image: ../Image Data/Paintings/training/Madhubani/p1.jpg, Predicted Class: Madhubani\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from PIL import Image\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "num_classes = 3  \n",
    "model = HierarchicalResNet(num_classes)  \n",
    "model.load_state_dict(torch.load('HierarchicalClassificationModel.pth'))\n",
    "model.eval()\n",
    "\n",
    "train_dataset = ImageFolder(root='../Image Data/Paintings/training', transform=transform)\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "def predict_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image).unsqueeze(0)  \n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    predicted_idx = predicted.item()\n",
    "    if 0 <= predicted_idx < len(class_names):  \n",
    "        predicted_class = class_names[predicted_idx]\n",
    "    else:\n",
    "        predicted_class = \"Image does not belong to any known class\"\n",
    "    return predicted_class\n",
    "\n",
    "image_paths = ['../Image Data/Monuments/train/Ajanta Caves/(1).jpg', '../Image Data/Paintings/training/Madhubani/p1.jpg']  \n",
    "for image_path in image_paths:\n",
    "    if 'Paintings' in image_path:\n",
    "        predicted_class = predict_image(image_path)\n",
    "        print(f'Image: {image_path}, Predicted Class: {predicted_class}')\n",
    "    else:\n",
    "        print(f'Image: {image_path}, Image belongs to a different category.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('3.9.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c9c1cb92ab039c53a0f0c6a3a1c445ea784bd0a545c5bb81dae74e9464ebef1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
