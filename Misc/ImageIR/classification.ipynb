{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Minibatch [10/90], Loss: 0.8829, Accuracy: 0.6062\n",
      "Epoch [1/2], Minibatch [20/90], Loss: 0.7106, Accuracy: 0.7516\n",
      "Epoch [1/2], Minibatch [30/90], Loss: 0.5896, Accuracy: 0.7974\n",
      "Epoch [1/2], Minibatch [40/90], Loss: 0.5066, Accuracy: 0.8313\n",
      "Epoch [1/2], Minibatch [50/90], Loss: 0.4479, Accuracy: 0.8516\n",
      "Epoch [1/2], Minibatch [60/90], Loss: 0.3986, Accuracy: 0.8714\n",
      "Epoch [1/2], Minibatch [70/90], Loss: 0.3676, Accuracy: 0.8824\n",
      "Epoch [1/2], Minibatch [80/90], Loss: 0.3372, Accuracy: 0.8943\n",
      "Epoch [1/2], Minibatch [90/90], Loss: 0.3139, Accuracy: 0.9027\n",
      "Epoch [1/2], Loss: 0.3139, Accuracy: 0.9027\n",
      "Epoch [2/2], Minibatch [10/90], Loss: 0.1102, Accuracy: 0.9766\n",
      "Epoch [2/2], Minibatch [20/90], Loss: 0.1083, Accuracy: 0.9773\n",
      "Epoch [2/2], Minibatch [30/90], Loss: 0.0961, Accuracy: 0.9818\n",
      "Epoch [2/2], Minibatch [40/90], Loss: 0.0933, Accuracy: 0.9824\n",
      "Epoch [2/2], Minibatch [50/90], Loss: 0.0918, Accuracy: 0.9822\n",
      "Epoch [2/2], Minibatch [60/90], Loss: 0.0903, Accuracy: 0.9823\n",
      "Epoch [2/2], Minibatch [70/90], Loss: 0.0917, Accuracy: 0.9817\n",
      "Epoch [2/2], Minibatch [80/90], Loss: 0.0906, Accuracy: 0.9814\n",
      "Epoch [2/2], Minibatch [90/90], Loss: 0.0883, Accuracy: 0.9822\n",
      "Epoch [2/2], Loss: 0.0883, Accuracy: 0.9822\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from PIL import Image\n",
    "\n",
    "class HierarchicalResNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(HierarchicalResNet, self).__init__()\n",
    "        self.resnet = resnet18(pretrained=True)\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        self.fc_class = nn.Linear(num_ftrs, num_classes) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.resnet(x)\n",
    "        class_output = self.fc_class(features)\n",
    "        return class_output\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class HierarchicalDataset(Dataset):\n",
    "    def __init__(self, data_dirs, transform=None):\n",
    "        self.data = []\n",
    "        self.class_map = {}\n",
    "        class_idx = 0\n",
    "        for class_dir in data_dirs:\n",
    "            class_label = os.path.basename(class_dir)\n",
    "            self.class_map[class_idx] = class_label\n",
    "            for sub_dir in os.listdir(class_dir):\n",
    "                sub_dir_path = os.path.join(class_dir, sub_dir)\n",
    "                if os.path.isdir(sub_dir_path):\n",
    "                    for img_file in os.listdir(sub_dir_path):\n",
    "                        img_path = os.path.join(sub_dir_path, img_file)\n",
    "                        _, ext = os.path.splitext(img_path)\n",
    "                        if ext.lower() in ['.jpg', '.jpeg', '.png', '.bmp', '.gif']: \n",
    "                            img = Image.open(img_path)\n",
    "                            if img.mode == 'RGB': \n",
    "                                self.data.append((img_path, class_idx))\n",
    "            class_idx += 1\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, class_idx = self.data[idx]\n",
    "        img = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, class_idx\n",
    "\n",
    "train_dirs = [\n",
    "    '../Image Data/Dance/train',\n",
    "    '../Image Data/Monuments/train',\n",
    "    '../Image Data/Paintings/training'\n",
    "]\n",
    "\n",
    "train_dataset = HierarchicalDataset(train_dirs, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "num_classes = 3  \n",
    "model = HierarchicalResNet(num_classes=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 2\n",
    "print_every = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    minibatch_counter = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        minibatch_counter += 1\n",
    "        if minibatch_counter % print_every == 0:\n",
    "            minibatch_loss = running_loss / total\n",
    "            minibatch_accuracy = correct / total\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Minibatch [{minibatch_counter}/{len(train_loader)}], Loss: {minibatch_loss:.4f}, Accuracy: {minibatch_accuracy:.4f}')\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_accuracy = correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
    "torch.save(model.state_dict(), 'HierarchicalClassificationModel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.1699, Accuracy: 0.1429\n",
      "Epoch [2/10], Loss: 1.9399, Accuracy: 0.3214\n",
      "Epoch [3/10], Loss: 1.7322, Accuracy: 0.4423\n",
      "Epoch [4/10], Loss: 1.5580, Accuracy: 0.5385\n",
      "Epoch [5/10], Loss: 1.4154, Accuracy: 0.6319\n",
      "Epoch [6/10], Loss: 1.2817, Accuracy: 0.6923\n",
      "Epoch [7/10], Loss: 1.1866, Accuracy: 0.7335\n",
      "Epoch [8/10], Loss: 1.0940, Accuracy: 0.7802\n",
      "Epoch [9/10], Loss: 1.0230, Accuracy: 0.8049\n",
      "Epoch [10/10], Loss: 0.9608, Accuracy: 0.8132\n",
      "Fine-tuning finished.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomResNet, self).__init__()\n",
    "        self.resnet = resnet18(pretrained=True)\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data = ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "train_dir = '../Image Data/Dance/train'\n",
    "#val_dir = '../Image Data/Dance/val'\n",
    "\n",
    "train_dataset = CustomDataset(train_dir, transform=transform)\n",
    "#val_dataset = CustomDataset(val_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "def check_labels(loader):\n",
    "    max_label = 0\n",
    "    for _, labels in loader:\n",
    "        max_label = max(max_label, labels.max().item())\n",
    "    return max_label\n",
    "\n",
    "max_train_label = check_labels(train_loader)\n",
    "num_classes = max_train_label + 1\n",
    "model = CustomResNet(num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "print_every = 7 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    minibatch_counter = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        minibatch_counter += 1\n",
    "        if minibatch_counter % print_every == 0:\n",
    "            minibatch_loss = running_loss / total\n",
    "            minibatch_accuracy = correct / total\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Minibatch [{minibatch_counter}/{len(train_loader)}], Loss: {minibatch_loss:.4f}, Accuracy: {minibatch_accuracy:.4f}')\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_accuracy = correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
    "\n",
    "print('Fine-tuning finished.')\n",
    "torch.save(model.state_dict(), 'Dance.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanoon/.pyenv/versions/3.9.10/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/hanoon/.pyenv/versions/3.9.10/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: ../Image Data/Paintings/training/Portrait/p2.jpg, Predicted Class: Portrait\n",
      "Image: ../Image Data/Dance/train/kathak/2.jpg, Predicted Class: Dance\n",
      "Image: ../Image Data/Monuments/train/Ajanta Caves/(1).jpg, Predicted Class: Monuments\n",
      "Image: ../Image Data/Paintings/training/Madhubani/p1.jpg, Predicted Class: Madhubani\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from PIL import Image\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "hierarchical_class_names = ['Dance', 'Monuments', 'Paintings']\n",
    "\n",
    "num_classes = 3  \n",
    "hierarchical_model = HierarchicalResNet(num_classes)  \n",
    "hierarchical_model.load_state_dict(torch.load('HierarchicalClassificationModel.pth'))\n",
    "hierarchical_model.eval()\n",
    "\n",
    "train_dataset = ImageFolder(root='../Image Data/Paintings/training', transform=transform)\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "painting_model = CustomResNet(len(class_names))  \n",
    "painting_model.load_state_dict(torch.load('Painting.pth'))\n",
    "painting_model.eval()\n",
    "\n",
    "def predict_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image).unsqueeze(0)  \n",
    "    with torch.no_grad():\n",
    "        output = hierarchical_model(image)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    hierarchical_predicted_label = hierarchical_class_names[predicted.item()]\n",
    "    \n",
    "    if hierarchical_predicted_label == \"Paintings\":\n",
    "        painting_output = painting_model(image)\n",
    "        _, painting_predicted = torch.max(painting_output, 1)\n",
    "        painting_predicted_class = class_names[painting_predicted.item()]\n",
    "        return painting_predicted_class\n",
    "    else:\n",
    "        return hierarchical_predicted_label\n",
    "\n",
    "image_paths = ['../Image Data/Paintings/training/Portrait/p2.jpg','../Image Data/Dance/train/kathak/2.jpg', '../Image Data/Monuments/train/Ajanta Caves/(1).jpg', '../Image Data/Paintings/training/Madhubani/p1.jpg']  \n",
    "for image_path in image_paths:\n",
    "    predicted_class = predict_image(image_path)\n",
    "    print(f'Image: {image_path}, Predicted Class: {predicted_class}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('3.9.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c9c1cb92ab039c53a0f0c6a3a1c445ea784bd0a545c5bb81dae74e9464ebef1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
